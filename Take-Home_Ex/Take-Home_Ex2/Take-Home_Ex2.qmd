---
title: "Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows"
author: "Su Sandi Cho Win"
date: "10 December 2023"
date-modified: "03 December 2023"
format: html
execute:
  echo: true
  eval: true
  warning: false
editor: visual
---

## 1. Overview

Understanding the factors motivating urban residents to commute early and assessing the consequences of removing public bus services pose significant challenges for transport operators and city planners. Traditionally, these questions are addressed through costly and time-consuming commuter surveys, often resulting in outdated information. However, as urban infrastructures become increasingly digital, the wealth of data generated by technologies like GPS and SMART cards presents an opportunity to track mobility patterns efficiently. Unfortunately, the rapid growth of geospatial data has outpaced our ability to harness it effectively, impacting the return on investment in data collection and management.

### 1.1. Objective

The project's main objectives stem from two critical factors.

1.  Despite the growing availability of open data for public use, there is a noticeable absence of practical research showcasing the integration, analysis, and modeling of these diverse data sources to inform policy decisions effectively.

2.  There is a general lack of real-world research demonstrating the practical application of geospatial data science and analysis (GDSA) to support decision-making processes.

Therefore, the project's primary goal is to conduct a case study illustrating the potential value of GDSA in seamlessly integrating publicly accessible data from various sources. This integration will be used to construct spatial interaction models aimed at uncovering the key factors influencing urban mobility patterns within the context of public bus transit.

## 2. Getting Started

The following code chunk installs and loads **tmap**, **sf**, **DT**, **jsonlite**, **performance**, **tidyverse**, **knitr**, **ggpubr**, **httr**, **jsonlite** packages into R environment. [`pacman()`](https://cran.r-project.org/web/packages/pacman/readme/README.html)is a R package.

```{r}
pacman::p_load(tmap, sf, DT, performance, tidyverse, knitr, ggpubr, httr, jsonlite)
```

## 3. Data Preparation

The datasets used for this study are:

### 3.1. Open Government Data

-   *Master Plan 2019 Subzone Boundary*, *HDB Property Information*, *School Directory and Information* from [data.gov.sg](https://beta.data.gov.sg/),

-   *Passenger Volume by Origin Destination Bus Stops*, *Bus Stop Location*, *Train Station* and *Train Station Exit Point* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html).

### **3.2. Specially collected data**

-   Geospatial data sets of the locations of business establishments, entertainments, food and beverage outlets, financial centres, leisure and recreation centres, retail and services stores/outlets for urban mobility study downloaded from [eLearn](https://elearn.smu.edu.sg/d2l/home/357628).

-   Geocoded version of *HDB Property Information* data from [data.gov.sg](https://beta.data.gov.sg/).

### 3.3. Importing the Data into R Environment

#### **3.3.1. Importing Geospatial Data into R**

The following code chunk utilizes the `st_read()` function from the **sf** package to import:

-   *BusStop* shapefile into R, creating a simple feature data frame named `busstop`, and

-   *MPSZ-2019* shapefile into R and save it as a sf data frame called `mpsz`.

```{r}
busstop <- st_read(dsn = "data/geospatial",
                   layer = "BusStop") %>%
  st_transform(crs = 3414) 
glimpse(busstop)
```

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
```

#### **3.3.2. Importing Attribute Data into R**

To begin, we utilize the `read_csv()` function from the **readr** package to import the *Passenger Volume by Origin Destination Bus Stops* dataset for the month of October 2023, downloaded from LTADataMall and name it as `odbus`.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv") 
glimpse(odbus)
```

The following code chunk converts the *ORIGIN_PT_CODE* and *DESTINATION_PT_CODE* columns in the `odbus` data frame into factor data types, making them suitable for further analysis. It then uses `glimpse()` function to verify if the conversion is successful.

```{r}
# Using tidyverse functions to convert these data values into factor data type.
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE) 
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)  
glimpse(odbus)
```

Next, we utilize the `read_csv()` function from the **readr** package to import the *HDB Property Information* data, downloaded from [data.gov.sg](https://beta.data.gov.sg/) and name it as `hdb`.

```{r}
hdb <- read_csv("data/aspatial/HDBPropertyInformation.csv") 
```

```{r}
geocode <- function(block, street) {
  base_url <- "https://www.onemap.gov.sg/api/common/elastic/search"
  address <- paste(block, street, sep = " ")
  query <- list("searchVal" = address, 
                "returnGeom" = "Y",
                "getAddrDetails" = "N",
                "pageNum" = "1")
  
  res <- GET(base_url, query = query)
  restext<-content(res, as="text")
  
  output <- fromJSON(restext)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

```{r}
hdb$LATITUDE <- 0
hdb$LONGITUDE <- 0

for (i in 1:nrow(hdb)){
  temp_output <- geocode(hdb[i, 1], hdb[i, 2])
  
  hdb$LATITUDE[i] <- temp_output$results.LATITUDE
  hdb$LONGITUDE[i] <- temp_output$results.LONGITUDE
}
```

The following code chunk is used to save the `hdb` data object in rds (R Data Serialization) format file named *hdb.rds* in the **data/rds** directory.

```{r}
write_rds(hdb, "data/rds/hdb.rds")
```

The following code chunk is used to import the saved *hdb.rds* into R environment and name it as `hdb_geo`.

```{r}
hdb_geo <- read_rds("data/rds/hdb.rds")
```

#### 3.3.3. **Extracting the study data**

For the purpose of this project, we will study data related to commuting patterns on weekdays during the busy afternoon rush hours (5pm \~ 8pm).

The following code chunk creates a new data frame called `wdap` by filtering the `odbus` data frame to retain only weekday data between **5PM** and **8PM**, grouping it by *ORIGIN_PT_CODE*, and then calculating the total number of trips for each origin point. Afterward, it displays the first few rows of the `wdap` data frame in a tabular format using the `kable()` function for visual inspection or reporting purposes.

```{r}
wdap <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 &
           TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))

kable(head(wdap))
```

The following code chunk is used to save the `wdap` data object in rds (R Data Serialization) format file named *wdap.rds* in the **data/rds** directory.

```{r}
write_rds(wdap, "data/rds/wdap.rds")
```

The following code chunk is used to import the saved *wdap.rds* into R environment.

```{r}
wdap <- read_rds("data/rds/wdap.rds")
```

```{r}
busstop_wdap <- left_join(busstop, wdap,
            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
  rename("ORIGIN_PT_CODE" = "BUS_STOP_N")
```

```{r}
hexagon_grid <- st_make_grid(busstop_wdap, c(750), what = "polygon", square = FALSE)

# To sf and add grid ID
hexagon_grid_sf <- st_sf(hexagon_grid) %>%
  # add grid ID
  mutate(grid_id = 1:length(lengths(hexagon_grid)))

# Perform spatial intersection to count points within each hexagon by bus stop origin
point_counts_origin <-
  st_intersection(hexagon_grid_sf, busstop_wdap) %>%
  group_by(grid_id) %>%
  summarize(
    TOT_TRIPS = sum(TRIPS, na.rm = TRUE),
    ORIGIN_PT_CODE = paste(ORIGIN_PT_CODE, collapse = ", ")
  )

# Merge the point counts back into the honeycomb grid by bus stop origin
hexagon_grid_sf_origin <- hexagon_grid_sf %>%
  st_join(point_counts_origin, by = "grid_id")

# remove grid without value of 0 (i.e. no points in side that grid)
honeycomb_count_origin <-
  filter(hexagon_grid_sf_origin, TOT_TRIPS > 0)

```

```{r}
tmap_mode("view")
tm_shape(honeycomb_count_origin) +
  tm_fill(
    col = "TOT_TRIPS",
    palette = "Reds",
    style = "quantile",
    title = "Number of Trips by Bus Stop Origin",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c("Number of Trips: " = "TOT_TRIPS",
                   "Bus STOP ORIGIN:" = "ORIGIN_PT_CODE"),
    popup.format = list(
      TOT_TRIPS = list(format = "f", digits = 0),
      ORIGIN_PT_CODE = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)
  
```

### **3.4. Data Wrangling**

### **3.4.1. Combining Busstop and mpsz**

The following code chunk populates the planning subzone code (i.e. *SUBZONE_C*) of `mpsz` sf data frame into `busstop` sf data frame.

```{r}
busstop_mpsz <- st_intersection(busstop, mpsz) %>%
  select(BUS_STOP_N, SUBZONE_C) %>%
  st_drop_geometry()
```

-   `st_intersection()` is used to perform point and polygon overlay and the output will be in point sf object.

-   `select()` of **dplyr** package is then use to retain only *BUS_STOP_N* and *SUBZONE_C* in the `busstop_mpsz` sf data frame.

-   Five bus stops are excluded in the resultant data frame because they are outside of Singapore boundary.

```{r}
datatable(busstop_mpsz)
```

Before moving to the next step, it is wise to save the output into rds format.

```{r}
write_rds(busstop_mpsz, "data/rds/busstop_mpsz.rds")  
```

Next, we are going to append the planning subzone code from `busstop_mpsz` data frame onto `wdap` data frame.

```{r}
od_data <- left_join(wdap , busstop_mpsz,
                     by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = SUBZONE_C,
         DESTIN_BS = DESTINATION_PT_CODE)
```

Before we continue, the following code chunk is used to check for duplicating records.

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n() > 1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r}
od_data <- unique(od_data)
```

It is a good practice to confirm if the duplicating records issue has been addressed fully.

Next, we will update *od_data* data frame with the planning subzone codes.

```{r}
od_data <- left_join(od_data , busstop_mpsz,
                     by = c("DESTIN_BS" = "BUS_STOP_N")) 
```

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n() > 1) %>%
  ungroup()
```

```{r}
od_data <- unique(od_data)
```

```{r}
od_data <- od_data %>%
  rename(DESTIN_SZ = SUBZONE_C) %>%
  drop_na() %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarise(TRIPS = sum(TRIPS))
```

It is time to save the output into an rds file format.

```{r}
write_rds(od_data, "data/rds/od_data.rds")
```
